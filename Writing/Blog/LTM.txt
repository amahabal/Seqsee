A beacon for FARGonauts is a working program embodying Doug's credo "analogy is at the core of cognition".  And analogy requires memory: every so often a thought drags out some old all but forgotten memory that is just what was needed.  A current math problem that confounds us get easier as an analogous problem we have solved earlier pops up out of nowhere.  In sum, Seqsee requires memory.

Another plug for memory.  One objection that FARGonauts raise about analogy research that starts from a handcrafted input is that a harder problem of arriving At a representation from "raw input" is not addressed.  FARG projects do start with raw inputs.  Copycat's letter strings.  Seqsee's sequences.  And Phaeaco's images.  They are all raw.  Another part of FARG architectures has traditionally been handcrafted; the concepts in the Slipnet, their links, what codelets they launch and so forth.  Is there a way of softening this hardcoded stuff?  Harry's Phaeaco started down that road; it has the ability to learn new concepts which it can store on disk between runs. 


One final plug for memory.  If Seqsee is given very few terms to start with,  there is not enough structure to extrapolate from and it must appeal to earlier sequences to figure out how to proceed. This article explores the design decisions forced by an expanding long term memory.

A design for a FARG "memory module" has a few axioms that it must respect.  I present these axioms without much explanation here.

Axiom one.  The memory shall be a graph with nodes and links connecting these to each other.  Further, the nodes can be dormant or activated to various degrees, and their activation generally decays over time.  Links can be of different lengths and can spread activation.  The shorter the link, the easier activation flows.  Links can be gated by some node: if the node is active, the link shortens.